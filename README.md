# PhysX: AI Training Platform

A modern Python platform for training AI agents in physics-based game environments. PhysX combines a Pygame-powered game engine with PyTorch machine learning capabilities to create an ideal environment for AI research and education.

## ğŸš€ Features

- **Game Engine:** Built on Pygame with physics simulation capabilities
- **AI Training:** Reinforcement learning and supervised learning frameworks
- **GPU Acceleration:** CUDA support for faster model training
- **Multiple Demos:** Ready-to-run examples to get started quickly
- **Extensible Design:** Modular architecture that's easy to customize

## ğŸ”§ Setup

### Prerequisites

- Python 3.8 or higher
- Virtual environment tool (venv, conda, etc.)
- GPU with CUDA support (optional, but recommended for AI training)

### Installation

1. **Create and activate a virtual environment:**

   ```bash
   # Windows
   python -m venv venv
   .\venv\Scripts\Activate.ps1
   
   # macOS/Linux
   python -m venv venv
   source venv/bin/activate
   ```

2. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

3. **Install the package in development mode:**

   ```bash
   pip install -e .
   ```

4. **Fetch game assets:**

   ```bash
   python scripts/fetch_assets.py
   ```

## ğŸ® Running the Platform

### Core Game

Run the main game engine with the following command:

```bash
ai-trainer
```

### Pygame Zero Demo

Try the simplified Pygame Zero demo:

```bash
pgzrun demos/pgz_demo/game_zero.py
```

## ğŸ§  AI Training

PhysX supports multiple AI training paradigms:

### Reinforcement Learning

- Vectorized environments in Pymunk
- Policy networks (MLP) trained via PPO
- GPU acceleration with PyTorch
- Real-time inference driving entity behavior

### Supervised Learning

- Custom data loaders for training datasets
- Model architecture examples for game environments
- Demonstration capabilities to visualize learning

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ ai_platform_trainer/       # Core package
â”‚   â”œâ”€â”€ __main__.py            # 'ai-trainer' entry point
â”‚   â”œâ”€â”€ agents/                # RL policies & training loops
â”‚   â”œâ”€â”€ core/                  # Config, logging, core utilities
â”‚   â”œâ”€â”€ cpp/                   # CUDA/C++ acceleration code
â”‚   â”œâ”€â”€ engine/                # Game engine components
â”‚   â”‚   â”œâ”€â”€ entities/          # Game entities (player, enemies, etc.)
â”‚   â”‚   â”œâ”€â”€ collision.py       # Physics collision handling
â”‚   â”‚   â”œâ”€â”€ display_manager.py # Display and window management
â”‚   â”‚   â”œâ”€â”€ game.py            # Main game loop
â”‚   â”‚   â”œâ”€â”€ input_handler.py   # User input processing
â”‚   â”‚   â”œâ”€â”€ menu.py            # UI menu system
â”‚   â”‚   â””â”€â”€ renderer.py        # Graphics rendering
â”‚   â””â”€â”€ supervised/            # Supervised learning components
â”œâ”€â”€ assets/sprites/            # Game assets (CC0 licensed)
â”œâ”€â”€ demos/                     # Example implementations
â”œâ”€â”€ scripts/                   # Utility scripts
â””â”€â”€ [configuration files]      # Project configuration
```

## ğŸ”„ How It Works

### Game Loop

1. **Input & AI Actions:** Process user input and AI agent decisions
2. **Physics & Updates:** Update entity positions and physics simulations
3. **Rendering:** Draw the current game state at 60 FPS

### AI Agent Integration

1. **Environment Observation:** Capture game state for AI input
2. **Model Inference:** Process state through neural networks
3. **Action Selection:** Determine optimal actions based on policy
4. **Environment Interaction:** Execute actions and update game state

## ğŸ› ï¸ Extending the Platform

### Custom Entities

Create new entity types in `ai_platform_trainer/engine/entities/` by inheriting from the base `Entity` class.

### New Physics Demos

Add custom physics simulations by creating new components that use the collision system.

### AI Model Experiments

Implement custom neural network architectures in the supervised or reinforcement learning modules.

## ğŸ¤ Contributing

Contributions are welcome! Feel free to submit issues or pull requests.

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“¬ Contact

Email: drew@drewclark.io  
GitHub: @life423
